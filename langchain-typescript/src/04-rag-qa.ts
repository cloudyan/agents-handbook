import dotenv from "dotenv";
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { Chroma } from "@langchain/community/vectorstores/chroma";
import { OpenAIEmbeddings } from "@langchain/openai";
import axios from "axios";
import * as cheerio from "cheerio";

// åŠ è½½ç¯å¢ƒå˜é‡ï¼Œè¦†ç›–å·²å­˜åœ¨çš„å˜é‡
dotenv.config({ override: true });

async function ragQA() {
  console.log("ğŸ” æ£€ç´¢å¢å¼ºé—®ç­” (RAG) - LangChain TypeScript ç¤ºä¾‹");
  console.log("=".repeat(50));

  const apiKey = process.env.OPENAI_API_KEY;
  const baseURL = process.env.OPENAI_BASE_URL || "https://api.openai.com/v1";
  const modelName = process.env.MODEL_NAME || "gpt-3.5-turbo";

  if (!apiKey) {
    console.error("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");
    process.exit(1);
  }

  console.log("\nğŸ“¥ æ­£åœ¨åŠ è½½æ–‡æ¡£...");
  const url = "https://docs.langchain.com/docs/introduction";
  const response = await axios.get(url);
  const $ = cheerio.load(response.data);
  const text = $("main").text();

  console.log("âœ… æ–‡æ¡£åŠ è½½å®Œæˆ");
  console.log(`ğŸ“„ æ–‡æ¡£é•¿åº¦: ${text.length} å­—ç¬¦`);

  console.log("\nğŸ”ª æ­£åœ¨åˆ†å‰²æ–‡æ¡£...");
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  });

  const chunks = await splitter.splitText(text);
  console.log(`âœ… åˆ†å‰²å®Œæˆï¼Œå…± ${chunks.length} ä¸ªç‰‡æ®µ`);

  console.log("\nğŸ”¤ æ­£åœ¨åˆ›å»ºå‘é‡ç´¢å¼•...");
  const embeddings = new OpenAIEmbeddings({
    openAIApiKey: apiKey,
    configuration: { baseURL },
  });

  const vectorStore = await Chroma.fromTexts(chunks, {}, embeddings, {
    collectionName: "langchain-docs",
  });
  console.log("âœ… å‘é‡ç´¢å¼•åˆ›å»ºå®Œæˆ");

  console.log("\nğŸ¤– åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ...");
  const llm = new ChatOpenAI({
    modelName,
    openAIApiKey: apiKey,
    configuration: { baseURL },
    temperature: 0,
  });

  const prompt = ChatPromptTemplate.fromTemplate(`
è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜æ— æ³•å›ç­”ã€‚

ä¸Šä¸‹æ–‡:
{context}

é—®é¢˜: {question}

å›ç­”:
`);

  const retriever = vectorStore.asRetriever(3);

  async function ask(question: string): Promise<void> {
    console.log(`\nğŸ“¤ é—®é¢˜: ${question}`);
    console.log("-".repeat(50));

    const docs = await retriever.invoke(question);
    const context = docs.map((doc) => doc.pageContent).join("\n\n");

    const chain = prompt.pipe(llm);
    const result = await chain.invoke({ context, question });

    console.log(`ğŸ“¥ å›ç­”: ${result.content}`);
    console.log(`\nğŸ“š å¼•ç”¨äº† ${docs.length} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ`);
  }

  await ask("ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ");
  await ask("LangChain æœ‰å“ªäº›ä¸»è¦ç»„ä»¶ï¼Ÿ");

  console.log("\n" + "=".repeat(50));
  console.log("âœ… RAG é—®ç­”ç³»ç»Ÿè¿è¡Œå®Œæˆï¼");
}

ragQA().catch(console.error);
