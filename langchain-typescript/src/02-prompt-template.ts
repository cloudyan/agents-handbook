import dotenv from "dotenv";
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";

// åŠ è½½ç¯å¢ƒå˜é‡ï¼Œè¦†ç›–å·²å­˜åœ¨çš„å˜é‡
dotenv.config({ override: true });

async function promptTemplate() {
  console.log("ğŸ“ æç¤ºè¯æ¨¡æ¿ - LangChain TypeScript ç¤ºä¾‹");
  console.log("=".repeat(50));

  const apiKey = process.env.OPENAI_API_KEY;
  const baseURL = process.env.OPENAI_BASE_URL || "https://api.openai.com/v1";
  const modelName = process.env.MODEL_NAME || "gpt-3.5-turbo";

  if (!apiKey) {
    console.error("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");
    process.exit(1);
  }

  const llm = new ChatOpenAI({
    modelName,
    openAIApiKey: apiKey,
    configuration: { baseURL },
    temperature: 0.7,
  });

  const prompt = ChatPromptTemplate.fromMessages([
    ["system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{topic}ä¸“å®¶ã€‚è¯·ç”¨ç®€æ´ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”é—®é¢˜ã€‚"],
    ["human", "{input}"],
  ]);

  const chain = prompt.pipe(llm);

  console.log("\nğŸ“¤ ç¤ºä¾‹1: JavaScript ä¸“å®¶");
  console.log("-".repeat(50));
  const result1 = await chain.invoke({
    topic: "JavaScript",
    input: "ä»€ä¹ˆæ˜¯é—­åŒ…ï¼Ÿ",
  });
  console.log(`ğŸ“¥ å›ç­”: ${result1.content}`);

  console.log("\nğŸ“¤ ç¤ºä¾‹2: Python ä¸“å®¶");
  console.log("-".repeat(50));
  const result2 = await chain.invoke({
    topic: "Python",
    input: "ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ",
  });
  console.log(`ğŸ“¥ å›ç­”: ${result2.content}`);

  console.log("\n" + "=".repeat(50));
  console.log("âœ… ç¤ºä¾‹è¿è¡Œå®Œæˆï¼");
}

promptTemplate().catch(console.error);
