import dotenv from "dotenv";
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage } from "@langchain/core/messages";

// åŠ è½½ç¯å¢ƒå˜é‡ï¼Œè¦†ç›–å·²å­˜åœ¨çš„å˜é‡
dotenv.config({ override: true });

async function helloChain() {
  console.log("ğŸ¦œ Hello Chain - LangChain TypeScript ç¤ºä¾‹");
  console.log("=".repeat(50));

  const apiKey = process.env.OPENAI_API_KEY;
  const baseURL = process.env.OPENAI_BASE_URL || "https://api.openai.com/v1";
  const modelName = process.env.MODEL_NAME || "gpt-3.5-turbo";

  if (!apiKey) {
    console.error("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");
    process.exit(1);
  }

  const llm = new ChatOpenAI({
    modelName,
    openAIApiKey: apiKey,
    configuration: { baseURL },
    temperature: 0.7,
    // verbose: true, // å¦‚æœéœ€è¦è°ƒè¯•ä¿¡æ¯ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Š
  });

  const response = await llm.invoke([
    new HumanMessage("ç”¨ä¸€å¥è¯ä»‹ç» LangChain æ˜¯ä»€ä¹ˆï¼Ÿ"),
  ]).catch((error) => {
    console.error("âŒ LLM è°ƒç”¨å¤±è´¥:", error);
    throw error;
  });

  console.log("\nğŸ“¤ ç”¨æˆ·è¾“å…¥:");
  console.log("  ç”¨ä¸€å¥è¯ä»‹ç» LangChain æ˜¯ä»€ä¹ˆï¼Ÿ");

  console.log("\nğŸ“¥ æ¨¡å‹å›å¤:");
  console.log(`  ${response.content}`);

  console.log("\n" + "=".repeat(50));
  console.log("âœ… ç¤ºä¾‹è¿è¡Œå®Œæˆï¼");
}

helloChain().catch(console.error);
