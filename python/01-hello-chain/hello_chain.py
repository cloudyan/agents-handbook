#!/usr/bin/env python3
"""
01 - Hello Chain
æœ€ç®€å•çš„ LangChain ç¤ºä¾‹
"""

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆè¦†ç›–å…¨å±€ç¯å¢ƒå˜é‡ï¼‰
load_dotenv(override=True)


def main():
    print("ğŸ¦œğŸ”— 01 - Hello Chain")
    print("=" * 40)

    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL")
    model_name = os.getenv("MODEL_NAME", "gpt-3.5-turbo")

    if not api_key:
        print("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return 1

    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from pydantic import SecretStr

        print("âœ“ LangChain ç»„ä»¶å¯¼å…¥å®Œæˆ")

        llm = ChatOpenAI(
            model=model_name,
            temperature=0.7,
            api_key=SecretStr(api_key),
            base_url=base_url
        )
        print(f"âœ“ OpenAI æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (model={model_name})")

        prompt_template = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›ç®€æ´è€Œæœ‰ç”¨çš„å›ç­”ï¼š
""")
        print("âœ“ æç¤ºè¯æ¨¡æ¿åˆ›å»ºå®Œæˆ")

        chain = prompt_template | llm | StrOutputParser()
        print("âœ“ LCEL Chain åˆ›å»ºå®Œæˆ")

        question = "ä»€ä¹ˆæ˜¯ LangChainï¼Ÿè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ã€‚"
        print(f"\né—®é¢˜ï¼š{question}")

        response = chain.invoke({"question": question})
        print(f"\nå›ç­”ï¼š{response}")

        print("\nğŸ‰ Hello Chain è¿è¡ŒæˆåŠŸï¼")

    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯ï¼š{e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–ï¼špip install -r requirements.txt")
        return 1
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯ï¼š{e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
