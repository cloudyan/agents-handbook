{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Hello Chain\n",
    "\n",
    "最简单的 LangChain 示例，演示如何创建一个基本的 LLMChain。\n",
    "\n",
    "## 学习目标\n",
    "- 理解 LangChain 的基本概念\n",
    "- 创建第一个 LLMChain\n",
    "- 使用 OpenAI 模型进行文本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 环境配置完成\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量（覆盖全局环境变量）\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# 检查 API 密钥\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    raise ValueError(\"请设置 OPENAI_API_KEY 环境变量\")\n",
    "\n",
    "print(\"✓ 环境配置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 导入 LangChain 核心组件\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.prompts'"
     ]
    }
   ],
   "source": [
    "# 导入 LangChain 核心组件\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import SecretStr\n",
    "\n",
    "print(\"✓ LangChain 组件导入完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 初始化 OpenAI 模型（从环境变量读取配置）\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "base_url = os.getenv('OPENAI_BASE_URL')\n",
    "model_name = os.getenv('MODEL_NAME', 'gpt-3.5-turbo')\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    temperature=0.7,\n",
    "    api_key=SecretStr(api_key),\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "print(f\"✓ OpenAI 模型初始化完成 (model={model_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 创建提示词模板\n",
    "# 这是给 AI 的指令，告诉它应该如何回答\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "你是一个友好的 AI 助手。请用中文回答用户的问题。\n",
    "\n",
    "用户问题：{question}\n",
    "\n",
    "请提供简洁而有用的回答：\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ 提示词模板创建完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 创建 LCEL Chain\n",
    "# 使用 LCEL 语法将模型和提示词模板组合成一个链\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "print(\"✓ LCEL Chain 创建完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 测试我们的第一个 Chain\n",
    "question = \"什么是 LangChain？请简单介绍一下。\"\n",
    "\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(f\"问题：{question}\")\n",
    "print(f\"回答：{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 尝试更多问题\n",
    "test_questions = [\n",
    "    \"Python 有哪些优点？\",\n",
    "    \"如何学习机器学习？\",\n",
    "    \"请推荐几本编程书籍\"\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n--- 测试 {i} ---\")\n",
    "    print(f\"问题：{q}\")\n",
    "    \n",
    "    response = chain.invoke({\"question\": q})\n",
    "    print(f\"回答：{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 直接使用模型（不使用 Chain）\n",
    "print(\"\\n=== 直接使用模型对比 ===\")\n",
    "\n",
    "messages = [HumanMessage(content=\"你好！请介绍一下你自己。\")]\n",
    "direct_response = llm.invoke(messages)\n",
    "\n",
    "print(f\"直接调用结果：{direct_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "在这个示例中，我们学习了：\n",
    "\n",
    "1. **ChatOpenAI**: LangChain 对 OpenAI API 的封装\n",
    "2. **ChatPromptTemplate**: 用于创建结构化的提示词\n",
    "3. **LLMChain**: 将模型和提示词组合成可重用的链\n",
    "\n",
    "### 关键概念\n",
    "- **LLM**: 大语言模型（如 GPT-3.5, GPT-4）\n",
    "- **Prompt**: 给模型的指令或问题\n",
    "- **Chain**: 将多个组件串联起来的工作流\n",
    "\n",
    "### 下一步\n",
    "尝试修改提示词模板，改变 AI 的角色设定，或者调整 temperature 参数看看效果变化！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
