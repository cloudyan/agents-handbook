{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Hello Chain\n",
    "\n",
    "æœ€ç®€å•çš„ LangChain ç¤ºä¾‹ï¼Œæ¼”ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„ LLMChainã€‚\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£ LangChain çš„åŸºæœ¬æ¦‚å¿µ\n",
    "- åˆ›å»ºç¬¬ä¸€ä¸ª LLMChain\n",
    "- ä½¿ç”¨ OpenAI æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ç¯å¢ƒé…ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆè¦†ç›–å…¨å±€ç¯å¢ƒå˜é‡ï¼‰\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# æ£€æŸ¥ API å¯†é’¥\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    raise ValueError(\"è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡\")\n",
    "\n",
    "print(\"âœ“ ç¯å¢ƒé…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LangChain ç»„ä»¶å¯¼å…¥å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥ LangChain æ ¸å¿ƒç»„ä»¶\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import SecretStr\n",
    "\n",
    "print(\"âœ“ LangChain ç»„ä»¶å¯¼å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ OpenAI æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (model=qwen3-max)\n"
     ]
    }
   ],
   "source": [
    "# 1. åˆå§‹åŒ– OpenAI æ¨¡å‹ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼‰\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')\n",
    "model_name = os.getenv(\"MODEL_NAME\", \"gpt-3.5-turbo\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    temperature=0.7,\n",
    "    api_key=SecretStr(api_key),\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "print(f\"âœ“ OpenAI æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (model={model_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æç¤ºè¯æ¨¡æ¿åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# 2. åˆ›å»ºæç¤ºè¯æ¨¡æ¿\n",
    "# è¿™æ˜¯ç»™ AI çš„æŒ‡ä»¤ï¼Œå‘Šè¯‰å®ƒåº”è¯¥å¦‚ä½•å›ç­”\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
    "\n",
    "ç”¨æˆ·é—®é¢˜ï¼š{question}\n",
    "\n",
    "è¯·æä¾›ç®€æ´è€Œæœ‰ç”¨çš„å›ç­”ï¼š\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ“ æç¤ºè¯æ¨¡æ¿åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LCEL Chain åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# 3. åˆ›å»º LCEL Chain\n",
    "# ä½¿ç”¨ LCEL è¯­æ³•å°†æ¨¡å‹å’Œæç¤ºè¯æ¨¡æ¿ç»„åˆæˆä¸€ä¸ªé“¾\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "print(\"âœ“ LCEL Chain åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜ï¼šä»€ä¹ˆæ˜¯ LangChainï¼Ÿè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ã€‚\n",
      "å›ç­”ï¼šLangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ ChatGPTï¼‰åº”ç”¨çš„å¼€æºæ¡†æ¶ã€‚å®ƒå¸®åŠ©å¼€å‘è€…å°†è¯­è¨€æ¨¡å‹ä¸å¤–éƒ¨æ•°æ®ã€å·¥å…·å’Œè®°å¿†æœºåˆ¶ç»“åˆèµ·æ¥ï¼Œä»è€Œåˆ›å»ºæ›´æ™ºèƒ½ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ AI åº”ç”¨ï¼Œæ¯”å¦‚èŠå¤©æœºå™¨äººã€é—®ç­”ç³»ç»Ÿæˆ–è‡ªåŠ¨åŒ–åŠ©æ‰‹ã€‚ç®€å•æ¥è¯´ï¼ŒLangChain è®©å¤§æ¨¡å‹â€œèƒ½ç”¨ã€å¥½ç”¨ã€æ›´å¼ºå¤§â€ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 4. æµ‹è¯•æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ª Chain\n",
    "question = \"ä»€ä¹ˆæ˜¯ LangChainï¼Ÿè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ã€‚\"\n",
    "\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(f\"é—®é¢˜ï¼š{question}\")\n",
    "print(f\"å›ç­”ï¼š{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- æµ‹è¯• 1 ---\n",
      "é—®é¢˜ï¼šPython æœ‰å“ªäº›ä¼˜ç‚¹ï¼Ÿ\n",
      "å›ç­”ï¼šPython çš„ä¸»è¦ä¼˜ç‚¹åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. **è¯­æ³•ç®€æ´æ˜“è¯»**ï¼šä»£ç æ¥è¿‘è‡ªç„¶è¯­è¨€ï¼Œå­¦ä¹ å’Œä½¿ç”¨é—¨æ§›ä½ã€‚  \n",
      "2. **è·¨å¹³å°**ï¼šæ”¯æŒ Windowsã€macOSã€Linux ç­‰å¤šç§æ“ä½œç³»ç»Ÿã€‚  \n",
      "3. **ä¸°å¯Œçš„æ ‡å‡†åº“å’Œç¬¬ä¸‰æ–¹åº“**ï¼šè¦†ç›– Web å¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰å¤šä¸ªé¢†åŸŸã€‚  \n",
      "4. **ç¤¾åŒºæ´»è·ƒ**ï¼šæ‹¥æœ‰åºå¤§çš„å¼€å‘è€…ç¤¾åŒºï¼Œèµ„æºä¸°å¯Œï¼Œé—®é¢˜å®¹æ˜“è§£å†³ã€‚  \n",
      "5. **è§£é‡Šå‹è¯­è¨€**ï¼šæ— éœ€ç¼–è¯‘ï¼Œä¾¿äºå¿«é€Ÿå¼€å‘å’Œè°ƒè¯•ã€‚  \n",
      "6. **å¹¿æ³›åº”ç”¨**ï¼šé€‚ç”¨äºè„šæœ¬ç¼–å†™ã€è‡ªåŠ¨åŒ–ã€ç§‘å­¦è®¡ç®—ã€æœºå™¨å­¦ä¹ ç­‰å¤šç§åœºæ™¯ã€‚\n",
      "\n",
      "--- æµ‹è¯• 2 ---\n",
      "é—®é¢˜ï¼šå¦‚ä½•å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Ÿ\n",
      "å›ç­”ï¼šå­¦ä¹ æœºå™¨å­¦ä¹ å¯ä»¥æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š\n",
      "\n",
      "1. **æ‰“å¥½æ•°å­¦åŸºç¡€**ï¼šé‡ç‚¹æŒæ¡çº¿æ€§ä»£æ•°ã€æ¦‚ç‡ç»Ÿè®¡å’Œå¾®ç§¯åˆ†ã€‚\n",
      "2. **å­¦ä¹ ç¼–ç¨‹**ï¼šæ¨èä½¿ç”¨ Pythonï¼Œç†Ÿæ‚‰ NumPyã€Pandasã€Matplotlib ç­‰åº“ã€‚\n",
      "3. **ç†è§£æ ¸å¿ƒæ¦‚å¿µ**ï¼šå¦‚ç›‘ç£/æ— ç›‘ç£å­¦ä¹ ã€è¿‡æ‹Ÿåˆã€åå·®-æ–¹å·®æƒè¡¡ç­‰ã€‚\n",
      "4. **åŠ¨æ‰‹å®è·µ**ï¼šé€šè¿‡ Kaggleã€å¤©æ± ç­‰å¹³å°åšé¡¹ç›®ï¼Œæˆ–å¤ç°ç»å…¸ç®—æ³•ã€‚\n",
      "5. **ç³»ç»Ÿå­¦ä¹ è¯¾ç¨‹**ï¼šæ¨è Coursera ä¸Šçš„ã€Šæœºå™¨å­¦ä¹ ã€‹ï¼ˆAndrew Ngï¼‰æˆ–å›½å†…ä¼˜è´¨ MOOCã€‚\n",
      "6. **é˜…è¯»èµ„æ–™**ï¼šå¦‚ã€ŠHands-On Machine Learningã€‹ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ç­‰ä¹¦ç±ã€‚\n",
      "\n",
      "åšæŒç†è®ºç»“åˆå®è·µï¼Œå¾ªåºæ¸è¿›ï¼Œä½ ä¼šé€æ­¥æŒæ¡æœºå™¨å­¦ä¹ ï¼\n",
      "\n",
      "--- æµ‹è¯• 3 ---\n",
      "é—®é¢˜ï¼šè¯·æ¨èå‡ æœ¬ç¼–ç¨‹ä¹¦ç±\n",
      "å›ç­”ï¼šå½“ç„¶ï¼ä»¥ä¸‹æ˜¯å‡ æœ¬å¹¿å—å¥½è¯„çš„ç¼–ç¨‹ä¹¦ç±ï¼Œé€‚åˆä¸åŒé˜¶æ®µçš„å­¦ä¹ è€…ï¼š\n",
      "\n",
      "1. **ã€Šä»£ç å¤§å…¨ã€‹ï¼ˆSteve McConnellï¼‰** â€“ è½¯ä»¶æ„å»ºçš„ç»å…¸æŒ‡å—ï¼Œé€‚åˆæå‡ç¼–ç¨‹å®è·µèƒ½åŠ›ã€‚  \n",
      "2. **ã€Šç¨‹åºå‘˜ä¿®ç‚¼ä¹‹é“ã€‹ï¼ˆAndrew Hunt & David Thomasï¼‰** â€“ æ¶µç›–å®ç”¨ç¼–ç¨‹åŸåˆ™ä¸æŠ€å·§ï¼Œé€‚åˆåˆå­¦è€…åˆ°ä¸­çº§å¼€å‘è€…ã€‚  \n",
      "3. **ã€Šç®—æ³•å¯¼è®ºã€‹ï¼ˆThomas H. Cormen ç­‰ï¼‰** â€“ ç®—æ³•é¢†åŸŸçš„æƒå¨æ•™æï¼Œé€‚åˆæ·±å…¥å­¦ä¹ æ•°æ®ç»“æ„ä¸ç®—æ³•ã€‚  \n",
      "4. **ã€Šä½ ä¸çŸ¥é“çš„JavaScriptã€‹ç³»åˆ—ï¼ˆKyle Simpsonï¼‰** â€“ æ·±å…¥ç†è§£ JavaScript æ ¸å¿ƒæœºåˆ¶ï¼Œé€‚åˆå‰ç«¯å¼€å‘è€…ã€‚  \n",
      "5. **ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹ï¼ˆEric Matthesï¼‰** â€“ é€‚åˆé›¶åŸºç¡€å­¦ä¹  Pythonï¼Œé¡¹ç›®é©±åŠ¨ï¼Œä¸Šæ‰‹å¿«ã€‚\n",
      "\n",
      "æ ¹æ®ä½ çš„ç¼–ç¨‹è¯­è¨€å’Œç›®æ ‡é€‰æ‹©åˆé€‚çš„ä¹¦ä¼šæ›´æœ‰æ•ˆå“¦ï¼\n"
     ]
    }
   ],
   "source": [
    "# 5. å°è¯•æ›´å¤šé—®é¢˜\n",
    "test_questions = [\n",
    "    \"Python æœ‰å“ªäº›ä¼˜ç‚¹ï¼Ÿ\",\n",
    "    \"å¦‚ä½•å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
    "    \"è¯·æ¨èå‡ æœ¬ç¼–ç¨‹ä¹¦ç±\"\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n--- æµ‹è¯• {i} ---\")\n",
    "    print(f\"é—®é¢˜ï¼š{q}\")\n",
    "\n",
    "    response = chain.invoke({\"question\": q})\n",
    "    print(f\"å›ç­”ï¼š{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ç›´æ¥ä½¿ç”¨æ¨¡å‹å¯¹æ¯” ===\n",
      "ç›´æ¥è°ƒç”¨ç»“æœï¼šä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\n",
      "\n",
      "æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼ˆQwenï¼‰ï¼Œæ˜¯ç”±é˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„é€šä¹‰å®éªŒå®¤è‡ªä¸»ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ï¼ˆæ¯”å¦‚å†™æ•…äº‹ã€å†™å…¬æ–‡ã€å†™é‚®ä»¶ã€å†™å‰§æœ¬ã€é€»è¾‘æ¨ç†ã€ç¼–ç¨‹ç­‰ï¼‰ã€è¡¨è¾¾è§‚ç‚¹ï¼Œç”šè‡³ç©æ¸¸æˆç­‰ã€‚\n",
      "\n",
      "æˆ‘æ”¯æŒå¤šç§è¯­è¨€ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä¸­æ–‡ã€è‹±æ–‡ã€å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ç­‰ï¼Œèƒ½å¤Ÿæ»¡è¶³å›½é™…åŒ–çš„ä½¿ç”¨éœ€æ±‚ã€‚åŒæ—¶ï¼Œæˆ‘ä¹Ÿå…·å¤‡è¾ƒå¼ºçš„å¯¹è¯ç†è§£èƒ½åŠ›ï¼Œç»è¿‡å¤šè½®è¿­ä»£å’Œä¼˜åŒ–ï¼Œèƒ½æ›´å‡†ç¡®åœ°ç†è§£ä¸ç”¨æˆ·äº¤äº’çš„å¯¹è¯å†å²ï¼Œæä¾›æ›´è‡ªç„¶ã€æµç•…çš„å¯¹è¯ä½“éªŒã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼æˆ‘ä¼šå°½åŠ›ä¸ºä½ æä¾›æ”¯æŒã€‚\n"
     ]
    }
   ],
   "source": [
    "# 6. ç›´æ¥ä½¿ç”¨æ¨¡å‹ï¼ˆä¸ä½¿ç”¨ Chainï¼‰\n",
    "print(\"\\n=== ç›´æ¥ä½¿ç”¨æ¨¡å‹å¯¹æ¯” ===\")\n",
    "\n",
    "messages = [HumanMessage(content=\"ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\")]\n",
    "direct_response = llm.invoke(messages)\n",
    "\n",
    "print(f\"ç›´æ¥è°ƒç”¨ç»“æœï¼š{direct_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ï¼š\n",
    "\n",
    "1. **ChatOpenAI**: LangChain å¯¹ OpenAI API çš„å°è£…\n",
    "2. **ChatPromptTemplate**: ç”¨äºåˆ›å»ºç»“æ„åŒ–çš„æç¤ºè¯\n",
    "3. **LLMChain**: å°†æ¨¡å‹å’Œæç¤ºè¯ç»„åˆæˆå¯é‡ç”¨çš„é“¾\n",
    "\n",
    "### å…³é”®æ¦‚å¿µ\n",
    "- **LLM**: å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPT-3.5, GPT-4ï¼‰\n",
    "- **Prompt**: ç»™æ¨¡å‹çš„æŒ‡ä»¤æˆ–é—®é¢˜\n",
    "- **Chain**: å°†å¤šä¸ªç»„ä»¶ä¸²è”èµ·æ¥çš„å·¥ä½œæµ\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "å°è¯•ä¿®æ”¹æç¤ºè¯æ¨¡æ¿ï¼Œæ”¹å˜ AI çš„è§’è‰²è®¾å®šï¼Œæˆ–è€…è°ƒæ•´ temperature å‚æ•°çœ‹çœ‹æ•ˆæœå˜åŒ–ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents Handbook",
   "language": "python",
   "name": "agents-handbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
