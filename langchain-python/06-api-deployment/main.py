#!/usr/bin/env python3
"""
06 - API Deployment
ä½¿ç”¨ FastAPI éƒ¨ç½²å¤©æ°”æ™ºèƒ½ä½“ä¸º HTTP æœåŠ¡ï¼Œå‚è€ƒ TypeScript ç‰ˆæœ¬å®ç°
"""

import os
import sys
import json
import httpx
import uvicorn
from typing import Dict, Any

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from dotenv import load_dotenv

load_dotenv(override=True)

if not os.getenv("OPENAI_API_KEY"):
    print("è­¦å‘Šï¼šè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")

if not os.getenv("OPENWEATHER_API_KEY"):
    print("è­¦å‘Šï¼šè¯·è®¾ç½® OPENWEATHER_API_KEY ç¯å¢ƒå˜é‡")

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

PORT = int(os.getenv("PORT", "8000"))

app = FastAPI(
    title="LangChain å¤©æ°”æ™ºèƒ½ä½“ API",
    description="åŸºäº LangChain çš„å¤©æ°”æŸ¥è¯¢å’Œæ™ºèƒ½å»ºè®® API",
    version="1.0.0",
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    message: str
    session_id: str | None = None


class HealthResponse(BaseModel):
    status: str
    langchain_available: bool
    openai_configured: bool
    openweather_configured: bool


try:
    from langchain.agents import create_agent
    from langchain.tools import tool
    from langchain_core.messages import HumanMessage
    from clients import create_model_client

    LANGCHAIN_AVAILABLE = True

    @tool
    def get_weather(location: str, days: int = 1) -> str:
        """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”é¢„æŠ¥ï¼ŒåŒ…æ‹¬æ¸©åº¦ã€å¤©æ°”çŠ¶å†µå’Œé™é›¨æ¦‚ç‡ã€‚

        Args:
            location (str): åŸå¸‚è‹±æ–‡åç§°ï¼Œä¾‹å¦‚ Beijing, Shanghai
            days (int): é¢„æŠ¥å¤©æ•°ï¼Œé»˜è®¤ä¸º1å¤©

        Returns:
            str: å¤©æ°”é¢„æŠ¥ä¿¡æ¯
        """
        try:
            api_key = os.getenv("OPENWEATHER_API_KEY")
            if not api_key:
                return "OPENWEATHER_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®"

            url = f"https://api.openweathermap.org/data/2.5/forecast"
            params = {
                "q": location,
                "appid": api_key,
                "units": "metric",
                "cnt": days * 8,
            }

            response = httpx.get(url, params=params, timeout=10.0)
            response.raise_for_status()
            data = response.json()

            forecasts = data["list"][: days * 8]
            result = f"{location} å¤©æ°”é¢„æŠ¥ï¼š\n"

            for item in forecasts:
                from datetime import datetime
                date = datetime.fromtimestamp(item["dt"]).strftime("%Y-%m-%d")
                condition = item["weather"][0]["description"]
                temp = item["main"]["temp"]
                result += f"{date} {condition}, æ¸©åº¦: {temp}Â°C\n"

            return result
        except Exception as e:
            return f"è·å–å¤©æ°”å¤±è´¥: {str(e)}"

    @tool
    def calculate(expression: str) -> str:
        """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼ã€‚

        Args:
            expression (str): æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ "2 + 3 * 4"

        Returns:
            str: è®¡ç®—ç»“æœ
        """
        try:
            result = eval(expression)
            return f"è®¡ç®—ç»“æœï¼š{result}"
        except:
            return "è®¡ç®—é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¡¨è¾¾å¼"

    llm = create_model_client(temperature=0, streaming=True)
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å›ç­”é—®é¢˜ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼Œå¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚"

    agent = create_agent(
        model=llm,
        tools=[get_weather, calculate],
        system_prompt=system_prompt,
    )

    print("âœ“ æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")

except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯ï¼š{e}")
    LANGCHAIN_AVAILABLE = False
    agent = None
except Exception as e:
    print(f"âŒ æ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
    LANGCHAIN_AVAILABLE = False
    agent = None


@app.get("/", response_model=Dict[str, Any])
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å› API ä¿¡æ¯"""
    return {
        "message": "LangChain æ™ºèƒ½ä½“ API Server (ä½¿ç”¨ createAgent)",
        "endpoints": {
            "/chat": "POST - ä¸ Agent å¯¹è¯ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰",
            "/chat/stream": "POST - ä¸ Agent å¯¹è¯ï¼ˆSSE æµå¼è¾“å‡ºï¼‰",
            "/health": "GET - å¥åº·æ£€æŸ¥",
        },
        "tools": ["get_weather", "calculate"],
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return HealthResponse(
        status="ok",
        langchain_available=LANGCHAIN_AVAILABLE,
        openai_configured=bool(os.getenv("OPENAI_API_KEY")),
        openweather_configured=bool(os.getenv("OPENWEATHER_API_KEY")),
    )


@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """æ™ºèƒ½ä½“å¯¹è¯ API"""
    global agent

    if not agent:
        raise HTTPException(status_code=500, detail="æ™ºèƒ½ä½“æœªåˆå§‹åŒ–")

    try:
        print(f"\n[{request.session_id or 'anonymous'}] ç”¨æˆ·é—®é¢˜: {request.message}")
        print("-" * 50)

        response = await agent.ainvoke(
            {"messages": [HumanMessage(content=request.message)]}
        )

        answer = response["messages"][-1].content

        print(f"\næœ€ç»ˆå›ç­”: {answer}")
        print("=" * 50)

        return {
            "message": answer,
            "timestamp": __import__("datetime").datetime.now().isoformat(),
        }
    except Exception as e:
        print(f"âŒ å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}")


async def generate_streaming_response(message: str, session_id: str | None = None):
    """ç”Ÿæˆæµå¼å“åº”"""
    try:
        print(f"\n[{session_id or 'anonymous'}] ç”¨æˆ·é—®é¢˜ (æµå¼): {message}")
        print("-" * 50)

        async for token, metadata in agent.astream(
            {"messages": [{"role": "user", "content": message}]},
            stream_mode="messages",
        ):
            if hasattr(token, "content_blocks"):
                for block in token.content_blocks:
                    if block.get("type") == "text":
                        text = block.get("text", "")
                        if text:
                            yield f"data: {json.dumps({'content': text, 'type': 'message'}, ensure_ascii=False)}\n\n"
                            print(f"[æµå¼è¾“å‡º] {text[:50]}...")

        yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"
        print("\næµå¼è¾“å‡ºå®Œæˆ")
        print("=" * 50)

    except Exception as e:
        print(f"âŒ å¤„ç†æµå¼è¯·æ±‚æ—¶å‡ºé”™: {e}")
        yield f"data: {json.dumps({'error': str(e), 'type': 'error'}, ensure_ascii=False)}\n\n"


@app.post("/chat/stream")
async def chat_stream_endpoint(request: ChatRequest):
    """æ™ºèƒ½ä½“å¯¹è¯ APIï¼ˆæµå¼è¾“å‡ºï¼‰"""
    global agent

    if not agent:
        raise HTTPException(status_code=500, detail="æ™ºèƒ½ä½“æœªåˆå§‹åŒ–")

    return StreamingResponse(
        generate_streaming_response(request.message, request.session_id),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "X-Accel-Buffering": "no",
        },
    )


if __name__ == "__main__":
    print("\nğŸš€ LangChain Agent API Server")
    print("=" * 50)
    print(f"æœåŠ¡å™¨è¿è¡Œåœ¨ http://localhost:{PORT}")
    print(f"API æ–‡æ¡£: http://localhost:{PORT}/")
    print("=" * 50)
    print("\nå¯ç”¨å·¥å…·:")
    print("  - get_weather: æŸ¥è¯¢å¤©æ°”é¢„æŠ¥")
    print("  - calculate: æ•°å­¦è®¡ç®—")

    print("\nç¤ºä¾‹è¯·æ±‚:")
    print(f'curl -X POST http://localhost:{PORT}/chat \\')
    print('  -H "Content-Type: application/json" \\')
    print('  -d \'{"message": "åŒ—äº¬æ˜å¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}\'')

    print("\nSSE æµå¼è¯·æ±‚:")
    print(f'curl -X POST http://localhost:{PORT}/chat/stream \\')
    print('  -H "Content-Type: application/json" \\')
    print('  -H "Accept: text/event-stream" \\')
    print('  -d \'{"message": "åŒ—äº¬æ˜å¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}\'')
    print("=" * 50)

    uvicorn.run(app, host="0.0.0.0", port=PORT, log_level="info")
