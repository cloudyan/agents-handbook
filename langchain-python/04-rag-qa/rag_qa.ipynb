{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 04 - RAG QA\n", "\n", "å­¦ä¹ æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œé€šè¿‡æ–‡æ¡£æ£€ç´¢æ¥æé«˜é—®ç­”çš„å‡†ç¡®æ€§ã€‚\n", "\n", "## å­¦ä¹ ç›®æ ‡\n", "- ç†è§£ RAG çš„åŸºæœ¬åŸç†å’Œä¼˜åŠ¿\n", "- æŒæ¡æ–‡æ¡£åŠ è½½å’Œé¢„å¤„ç†\n", "- å­¦ä¹ å‘é‡åŒ–å­˜å‚¨å’Œæ£€ç´¢\n", "- å®ç°å®Œæ•´çš„ RAG é—®ç­”ç³»ç»Ÿ"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# å¯¼å…¥å¿…è¦çš„åº“\n", "import os\n", "from dotenv import load_dotenv\n", "from pydantic import SecretStr\n", "\n", "# åŠ è½½ç¯å¢ƒå˜é‡\n", "load_dotenv(override=True)\n", "\n", "# æ£€æŸ¥ API å¯†é’¥\n", "if not os.getenv('OPENAI_API_KEY'):\n", "    raise ValueError(\"è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡\")\n", "\n", "# å¯¼å…¥ LangChain ç»„ä»¶\n", "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n", "from langchain_text_splitters import RecursiveCharacterTextSplitter\n", "from langchain_chroma import Chroma\n", "from langchain.chains import create_retrieval_chain\n", "from langchain.chains.combine_documents import create_stuff_documents_chain\n", "from langchain_community.document_loaders import TextLoader\n", "from langchain_core.prompts import ChatPromptTemplate\n", "\n", "print(\"âœ“ ç¯å¢ƒå’Œç»„ä»¶å¯¼å…¥å®Œæˆ\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. å‡†å¤‡æ–‡æ¡£æ•°æ®"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ï¼ˆå¦‚æœæ²¡æœ‰ç½‘ç»œï¼Œä½¿ç”¨æœ¬åœ°æ–‡æœ¬ï¼‰\n", "sample_docs = [\n", "    \"\"\"\n", "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”± Guido van Rossum äº 1991 å¹´é¦–æ¬¡å‘å¸ƒã€‚\n", "Python å…·æœ‰ç®€æ´æ˜äº†çš„è¯­æ³•ï¼Œæ˜“äºå­¦ä¹ å’Œä½¿ç”¨ï¼Œè¢«å¹¿æ³›åº”ç”¨äº Web å¼€å‘ã€\n", "æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½ã€è‡ªåŠ¨åŒ–è„šæœ¬ç­‰é¢†åŸŸã€‚\n", "\n", "Python çš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š\n", "- è¯­æ³•ç®€æ´ï¼Œå¯è¯»æ€§å¼º\n", "- æ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼ï¼ˆé¢å‘å¯¹è±¡ã€å‡½æ•°å¼ã€è¿‡ç¨‹å¼ï¼‰\n", "- ä¸°å¯Œçš„æ ‡å‡†åº“å’Œç¬¬ä¸‰æ–¹åº“\n", "- è·¨å¹³å°ï¼Œå¯åœ¨å¤šç§æ“ä½œç³»ç»Ÿä¸Šè¿è¡Œ\n", "- æ´»è·ƒçš„ç¤¾åŒºæ”¯æŒ\n", "\"\"\",\n", "    \"\"\"\n", "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹\n", "å­¦ä¹ å’Œæ”¹è¿›ã€‚æœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡åˆ†ææ•°æ®æ¥è¯†åˆ«æ¨¡å¼ï¼Œå¹¶åŸºäºè¿™äº›æ¨¡å¼åšå‡ºé¢„æµ‹æˆ–å†³ç­–ã€‚\n", "\n", "æœºå™¨å­¦ä¹ çš„ä¸»è¦ç±»å‹åŒ…æ‹¬ï¼š\n", "1. ç›‘ç£å­¦ä¹ ï¼šä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»\n", "2. æ— ç›‘ç£å­¦ä¹ ï¼šä»æ— æ ‡è®°çš„æ•°æ®ä¸­å‘ç°éšè—çš„æ¨¡å¼å’Œç»“æ„\n", "3. å¼ºåŒ–å­¦ä¹ ï¼šé€šè¿‡ä¸ç¯å¢ƒäº¤äº’å­¦ä¹ æœ€ä¼˜ç­–ç•¥\n", "\n", "å¸¸è§çš„æœºå™¨å­¦ä¹ ç®—æ³•æœ‰çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œã€æ”¯æŒå‘é‡æœºç­‰ã€‚\n", "\"\"\",\n", "    \"\"\"\n", "LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚å®ƒæä¾›äº†ä¸€å¥—å·¥å…·å’Œç»„ä»¶ï¼Œ\n", "å¸®åŠ©å¼€å‘è€…æ›´å®¹æ˜“åœ°åˆ›å»ºå¤æ‚çš„ AI åº”ç”¨ã€‚\n", "\n", "LangChain çš„æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š\n", "- æ¨¡å‹æŠ½è±¡ï¼šç»Ÿä¸€ä¸åŒ LLM æä¾›å•†çš„æ¥å£\n", "- æç¤ºè¯ç®¡ç†ï¼šåˆ›å»ºå’Œç®¡ç†å¤æ‚çš„æç¤ºè¯æ¨¡æ¿\n", "- é“¾å¼è°ƒç”¨ï¼šå°†å¤šä¸ªç»„ä»¶ä¸²è”æˆå·¥ä½œæµ\n", "- è®°å¿†ç®¡ç†ï¼šä¸ºå¯¹è¯ç³»ç»Ÿæ·»åŠ è®°å¿†åŠŸèƒ½\n", "- æ™ºèƒ½ä½“ï¼šåˆ›å»ºèƒ½å¤Ÿä½¿ç”¨å·¥å…·çš„è‡ªä¸»æ™ºèƒ½ä½“\n", "- ç´¢å¼•å’Œæ£€ç´¢ï¼šæ„å»º RAG ç³»ç»Ÿ\n", "\n", "LangChain æ”¯æŒ Python å’Œ JavaScript/TypeScriptï¼Œæ˜¯ç›®å‰æœ€å—æ¬¢è¿çš„ LLM åº”ç”¨å¼€å‘æ¡†æ¶ä¹‹ä¸€ã€‚\n", "\"\"\"\n", "]\n", "\n", "print(\"âœ“ ç¤ºä¾‹æ–‡æ¡£å‡†å¤‡å®Œæˆ\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ä¿å­˜æ–‡æ¡£åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆç”¨äºæ¼”ç¤ºï¼‰\n", "os.makedirs(\"temp_docs\", exist_ok=True)\n", "\n", "doc_files = [\n", "    (\"temp_docs/python_intro.txt\", sample_docs[0]),\n", "    (\"temp_docs/ml_intro.txt\", sample_docs[1]),\n", "    (\"temp_docs/langchain_intro.txt\", sample_docs[2])\n", "]\n", "\n", "for file_path, content in doc_files:\n", "    with open(file_path, 'w', encoding='utf-8') as f:\n", "        f.write(content.strip())\n", "\n", "print(\"âœ“ æ–‡æ¡£æ–‡ä»¶åˆ›å»ºå®Œæˆ\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. æ–‡æ¡£åŠ è½½å’Œé¢„å¤„ç†"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åŠ è½½æ–‡æ¡£\n", "loader = TextLoader(\"temp_docs/python_intro.txt\", encoding='utf-8')\n", "documents = loader.load()\n", "\n", "# åŠ è½½æ‰€æœ‰æ–‡æ¡£\n", "all_documents = []\n", "for file_path, _ in doc_files:\n", "    loader = TextLoader(file_path, encoding='utf-8')\n", "    docs = loader.load()\n", "    all_documents.extend(docs)\n", "\n", "print(f\"âœ“ åŠ è½½äº† {len(all_documents)} ä¸ªæ–‡æ¡£\")\n", "for i, doc in enumerate(all_documents):\n", "    print(f\"  æ–‡æ¡£ {i+1}: {doc.metadata.get('source', 'unknown')} ({len(doc.page_content)} å­—ç¬¦)\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æ–‡æ¡£åˆ†å‰²\n", "text_splitter = RecursiveCharacterTextSplitter(\n", "    chunk_size=500,  # æ¯ä¸ªåˆ†å—çš„æœ€å¤§å­—ç¬¦æ•°\n", "    chunk_overlap=50,  # åˆ†å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°\n", "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # åˆ†å‰²ä¼˜å…ˆçº§\n", ")\n", "\n", "splits = text_splitter.split_documents(all_documents)\n", "\n", "print(f\"âœ“ æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…± {len(splits)} ä¸ªåˆ†å—\")\n", "for i, split in enumerate(splits[:3]):  # æ˜¾ç¤ºå‰ 3 ä¸ªåˆ†å—\n", "    print(f\"\\n--- åˆ†å— {i+1} ---\")\n", "    print(f\"æ¥æºï¼š{split.metadata.get('source', 'unknown')}\")\n", "    print(f\"å†…å®¹é¢„è§ˆï¼š{split.page_content[:100]}...\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. å‘é‡åŒ–å­˜å‚¨"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®\n", "api_key = os.getenv(\"OPENAI_API_KEY\")\n", "base_url = os.getenv(\"OPENAI_BASE_URL\")\n", "\n", "# åˆå§‹åŒ– OpenAI åµŒå…¥æ¨¡å‹\n", "embeddings = OpenAIEmbeddings(api_key=SecretStr(api_key), base_url=base_url)\n", "\n", "print(\"âœ“ OpenAI åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åˆ›å»ºå‘é‡æ•°æ®åº“\n", "# ä½¿ç”¨ Chroma ä½œä¸ºå‘é‡å­˜å‚¨\n", "vectorstore = Chroma.from_documents(\n", "    documents=splits,\n", "    embedding=embeddings,\n", "    persist_directory=\"./chroma_db\"  # æŒä¹…åŒ–å­˜å‚¨ç›®å½•\n", ")\n", "\n", "print(\"âœ“ å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ\")\n", "print(f\"å­˜å‚¨äº† {len(splits)} ä¸ªæ–‡æ¡£åˆ†å—\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. æµ‹è¯•æ£€ç´¢åŠŸèƒ½"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æµ‹è¯•ç›¸ä¼¼æ€§æœç´¢\n", "query = \"Python çš„ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\"\n", "\n", "# æ£€ç´¢ç›¸å…³æ–‡æ¡£\n", "relevant_docs = vectorstore.similarity_search(query, k=3)  # è¿”å›æœ€ç›¸å…³çš„ 3 ä¸ªæ–‡æ¡£\n", "\n", "print(f\"æŸ¥è¯¢ï¼š{query}\")\n", "print(f\"\\næ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£ï¼š\")\n", "\n", "for i, doc in enumerate(relevant_docs):\n", "    print(f\"\\n--- æ–‡æ¡£ {i+1} ---\")\n", "    print(f\"æ¥æºï¼š{doc.metadata.get('source', 'unknown')}\")\n", "    print(f\"å†…å®¹ï¼š{doc.page_content}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æµ‹è¯•æ›´å¤šæŸ¥è¯¢\n", "test_queries = [\n", "    \"æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ\",\n", "    \"LangChain çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ\",\n", "    \"å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ\"\n", "]\n", "\n", "for query in test_queries:\n", "    print(f\"\\n=== æŸ¥è¯¢ï¼š{query} ===\")\n", "    docs = vectorstore.similarity_search(query, k=2)\n", "    \n", "    for i, doc in enumerate(docs):\n", "        print(f\"\\næ–‡æ¡£ {i+1}ï¼š\")\n", "        print(f\"{doc.page_content[:150]}...\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. åˆ›å»º RAG é—®ç­”ç³»ç»Ÿ"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®\n", "model_name = os.getenv(\"MODEL_NAME\", \"gpt-3.5-turbo\")\n", "\n", "# åˆå§‹åŒ– LLM\n", "llm = ChatOpenAI(\n", "    model=model_name,\n", "    temperature=0,\n", "    api_key=SecretStr(api_key),\n", "    base_url=base_url,\n", ")\n", "\n", "print(\"âœ“ LLM åˆå§‹åŒ–å®Œæˆ\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åˆ›å»ºè‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿\n", "prompt_template = ChatPromptTemplate.from_template(\n", "    \"\"\"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´\"æ ¹æ®æä¾›çš„æ–‡æ¡£ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜\"ã€‚\n", "\n", "ä¸Šä¸‹æ–‡ï¼š\n", "{context}\n", "\n", "é—®é¢˜ï¼š{input}\n", "\n", "è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ï¼š\"\"\"\n", ")\n", "\n", "print(\"âœ“ RAG æç¤ºè¯æ¨¡æ¿åˆ›å»ºå®Œæˆ\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åˆ›å»º RAG é“¾\n", "# åˆ›å»ºæ–‡æ¡£é“¾\n", "document_chain = create_stuff_documents_chain(llm, prompt_template)\n", "\n", "# åˆ›å»ºæ£€ç´¢é“¾\n", "retriever = vectorstore.as_retriever(\n", "    search_kwargs={\"k\": 3}  # æ£€ç´¢å‰ 3 ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£\n", ")\n", "qa_chain = create_retrieval_chain(retriever, document_chain)\n", "\n", "print(\"âœ“ RAG é—®ç­”é“¾åˆ›å»ºå®Œæˆ\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. æµ‹è¯• RAG é—®ç­”"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æµ‹è¯• RAG é—®ç­”\n", "questions = [\n", "    \"Python æœ‰å“ªäº›ä¸»è¦ç‰¹ç‚¹ï¼Ÿ\",\n", "    \"æœºå™¨å­¦ä¹ çš„ä¸»è¦ç±»å‹æœ‰å“ªäº›ï¼Ÿ\",\n", "    \"LangChain æä¾›å“ªäº›æ ¸å¿ƒåŠŸèƒ½ï¼Ÿ\",\n", "    \"å¦‚ä½•å­¦ä¹ äººå·¥æ™ºèƒ½ï¼Ÿ\",  # è¿™ä¸ªé—®é¢˜å¯èƒ½æ— æ³•ç›´æ¥å›ç­”\n", "    \"Python æ˜¯è°åˆ›å»ºçš„ï¼Ÿ\"\n", "]\n", "\n", "for question in questions:\n", "    print(f\"\\n=== é—®é¢˜ï¼š{question} ===\")\n", "    \n", "    # è·å–å›ç­”\n", "    result = qa_chain.invoke({\"input\": question})\n", "    \n", "    print(f\"å›ç­”ï¼š{result['answer']}\")\n", "    \n", "    # æ˜¾ç¤ºæºæ–‡æ¡£\n", "    if 'context' in result:\n", "        print(\"\\nå‚è€ƒæ¥æºï¼š\")\n", "        for i, doc in enumerate(result['context']):\n", "            source = doc.metadata.get('source', 'unknown')\n", "            print(f\"  {i+1}. {source}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. è¿›é˜¶åŠŸèƒ½"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æ¼”ç¤ºå¦‚ä½•æ·»åŠ æ–°æ–‡æ¡£\n", "new_doc_content = \"\"\"\n", "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚\n", "æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚\n", "\n", "å¸¸è§çš„æ·±åº¦å­¦ä¹ æ¡†æ¶åŒ…æ‹¬ TensorFlowã€PyTorchã€Keras ç­‰ã€‚\n", "è¿™äº›æ¡†æ¶æä¾›äº†æ„å»ºå’Œè®­ç»ƒç¥ç»ç½‘ç»œçš„å·¥å…·å’Œåº“ã€‚\n", "\"\"\"\n", "\n", "# ä¿å­˜æ–°æ–‡æ¡£\n", "with open(\"temp_docs/deep_learning.txt\", 'w', encoding='utf-8') as f:\n", "    f.write(new_doc_content.strip())\n", "\n", "# åŠ è½½å¹¶åˆ†å‰²æ–°æ–‡æ¡£\n", "new_loader = TextLoader(\"temp_docs/deep_learning.txt\", encoding='utf-8')\n", "new_docs = new_loader.load()\n", "new_splits = text_splitter.split_documents(new_docs)\n", "\n", "# æ·»åŠ åˆ°å‘é‡æ•°æ®åº“\n", "vectorstore.add_documents(new_splits)\n", "\n", "print(f\"âœ“ æ·»åŠ äº† {len(new_splits)} ä¸ªæ–°çš„æ–‡æ¡£åˆ†å—\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æµ‹è¯•æ–°æ·»åŠ çš„å†…å®¹\n", "new_questions = [\n", "    \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ\",\n", "    \"æœ‰å“ªäº›æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Ÿ\",\n", "    \"æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ\"\n", "]\n", "\n", "for question in new_questions:\n", "    print(f\"\\n=== é—®é¢˜ï¼š{question} ===\")\n", "    result = qa_chain.invoke({\"input\": question})\n", "    print(f\"å›ç­”ï¼š{result['answer']}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. æ€§èƒ½åˆ†æ"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åˆ†ææ£€ç´¢è´¨é‡\n", "def analyze_retrieval(query, k=3):\n", "    \"\"\"åˆ†ææ£€ç´¢ç»“æœçš„è´¨é‡\"\"\"\n", "    docs = vectorstore.similarity_search_with_score(query, k=k)\n", "    \n", "    print(f\"æŸ¥è¯¢ï¼š{query}\")\n", "    print(f\"\\næ£€ç´¢ç»“æœï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰ï¼š\")\n", "    \n", "    for i, (doc, score) in enumerate(docs):\n", "        print(f\"\\n{i+1}. ç›¸ä¼¼åº¦åˆ†æ•°ï¼š{score:.4f}\")\n", "        print(f\"   æ¥æºï¼š{doc.metadata.get('source', 'unknown')}\")\n", "        print(f\"   å†…å®¹ï¼š{doc.page_content[:100]}...\")\n", "\n", "# æµ‹è¯•ä¸åŒæŸ¥è¯¢çš„æ£€ç´¢æ•ˆæœ\n", "test_queries_for_analysis = [\n", "    \"Python ç¼–ç¨‹è¯­è¨€\",\n", "    \"ç¥ç»ç½‘ç»œ\",\n", "    \"AI åº”ç”¨å¼€å‘\"\n", "]\n", "\n", "for query in test_queries_for_analysis:\n", "    print(\"\\n\" + \"=\"*50)\n", "    analyze_retrieval(query)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. æ¸…ç†èµ„æº"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n", "import shutil\n", "\n", "def cleanup():\n", "    \"\"\"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œæ•°æ®åº“\"\"\"\n", "    try:\n", "        # åˆ é™¤ä¸´æ—¶æ–‡æ¡£\n", "        if os.path.exists(\"temp_docs\"):\n", "            shutil.rmtree(\"temp_docs\")\n", "            print(\"âœ“ ä¸´æ—¶æ–‡æ¡£å·²æ¸…ç†\")\n", "        \n", "        # åˆ é™¤å‘é‡æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰\n", "        # if os.path.exists(\"chroma_db\"):\n", "        #     shutil.rmtree(\"chroma_db\")\n", "        #     print(\"âœ“ å‘é‡æ•°æ®åº“å·²æ¸…ç†\")\n", "        \n", "    except Exception as e:\n", "        print(f\"æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}\")\n", "\n", "# å–æ¶ˆæ³¨é‡Šä»¥è¿è¡Œæ¸…ç†\n", "# cleanup()\n", "\n", "print(\"\\nğŸ‰ RAG QA ç¤ºä¾‹è¿è¡Œå®Œæˆï¼\")\n", "print(\"æç¤ºï¼šå¯ä»¥æ‰‹åŠ¨è¿è¡Œ cleanup() å‡½æ•°æ¸…ç†ä¸´æ—¶æ–‡ä»¶\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## æ€»ç»“\n", "\n", "åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ï¼š\n", "\n", "1. **æ–‡æ¡£åŠ è½½**: ä½¿ç”¨ TextLoader åŠ è½½æœ¬åœ°æ–‡æ¡£\n", "2. **æ–‡æ¡£åˆ†å‰²**: RecursiveCharacterTextSplitter å°†é•¿æ–‡æ¡£åˆ†å‰²æˆé€‚å½“å¤§å°çš„å—\n", "3. **å‘é‡åŒ–**: OpenAIEmbeddings å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º\n", "4. **å‘é‡å­˜å‚¨**: Chroma å‘é‡æ•°æ®åº“å­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£\n", "5. **RAG é“¾**: ä½¿ç”¨ create_retrieval_chain ç»„åˆæ£€ç´¢å’Œç”ŸæˆåŠŸèƒ½\n", "6. **è‡ªå®šä¹‰æç¤º**: è®¾è®¡é€‚åˆ RAG çš„æç¤ºè¯æ¨¡æ¿\n", "7. **åŠ¨æ€æ·»åŠ **: æ”¯æŒè¿è¡Œæ—¶æ·»åŠ æ–°æ–‡æ¡£\n", "8. **æ€§èƒ½åˆ†æ**: æ£€æŸ¥æ£€ç´¢è´¨é‡å’Œç›¸ä¼¼åº¦åˆ†æ•°\n", "\n", "### å…³é”®æ¦‚å¿µ\n", "- **Embeddings**: æ–‡æœ¬çš„æ•°å€¼è¡¨ç¤ºï¼Œç”¨äºè®¡ç®—ç›¸ä¼¼åº¦\n", "- **Vector Store**: å­˜å‚¨å’Œæ£€ç´¢å‘é‡çš„æ•°æ®åº“\n", "- **Retriever**: æ ¹æ®æŸ¥è¯¢æ£€ç´¢ç›¸å…³æ–‡æ¡£çš„ç»„ä»¶\n", "- **Chunk Size**: æ–‡æ¡£åˆ†å—çš„å¤§å°ï¼Œå½±å“æ£€ç´¢ç²¾åº¦å’Œæ€§èƒ½\n", "- **Overlap**: åˆ†å—é—´çš„é‡å ï¼Œç¡®ä¿ä¸Šä¸‹æ–‡è¿ç»­æ€§\n", "\n", "### æœ€ä½³å®è·µ\n", "1. **åˆ†å—å¤§å°**: 500-1000 å­—ç¬¦é€šå¸¸æ•ˆæœè¾ƒå¥½\n", "2. **é‡å è®¾ç½®**: 10-20% çš„åˆ†å—å¤§å°ä½œä¸ºé‡å \n", "3. **æ£€ç´¢æ•°é‡**: k=3-5 é€šå¸¸è¶³å¤Ÿ\n", "4. **æç¤ºè¯è®¾è®¡**: å¼ºè°ƒåŸºäºä¸Šä¸‹æ–‡å›ç­”\n", "5. **è´¨é‡æ£€æŸ¥**: å®šæœŸæ£€æŸ¥æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§\n", "\n", "### åº”ç”¨åœºæ™¯\n", "- çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ\n", "- æ–‡æ¡£æ£€ç´¢å’Œæ€»ç»“\n", "- å®¢æœæ”¯æŒç³»ç»Ÿ\n", "- å­¦æœ¯ç ”ç©¶è¾…åŠ©\n", "- ä¸ªäººçŸ¥è¯†ç®¡ç†\n", "\n", "### ä¸‹ä¸€æ­¥\n", "å°è¯•å°† RAG ä¸è®°å¿†ã€æ™ºèƒ½ä½“ç­‰åŠŸèƒ½ç»“åˆï¼Œæ„å»ºæ›´å¤æ‚çš„ AI åº”ç”¨ï¼"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.0"}}, "nbformat": 4, "nbformat_minor": 4}
